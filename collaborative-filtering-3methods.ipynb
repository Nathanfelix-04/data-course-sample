{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84de56a8",
   "metadata": {},
   "source": [
    "# Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688675f5",
   "metadata": {},
   "source": [
    "## 基礎建設"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import gzip, json\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib \n",
    "matplotlib.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32226db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff0f9d",
   "metadata": {},
   "source": [
    "## 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b66cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = getDF('/content/meta_All_Beauty.json.gz')\n",
    "ratings = pd.read_csv('/content/All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_json(\"meta_All_Beauty.json\", lines=True)\n",
    "ratings = pd.read_json('All_Beauty.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd77203",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[['asin', 'reviewerID', 'overall', 'unixReviewTime']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695362e3",
   "metadata": {},
   "source": [
    "## 去空值、重複&清洗rank、price欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79841e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_na(cell):\n",
    "    try:\n",
    "        if len(cell) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return cell\n",
    "    except:\n",
    "        return cell\n",
    "metadata_na = metadata.applymap(lambda x : empty_na(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_clean = metadata_na[['asin', 'title', 'rank', 'brand', 'description', 'price']]\n",
    "metadata_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_clean.duplicated(subset='asin').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_clean = metadata_clean.drop_duplicates(subset='asin').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc204d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_clean['rank'] = metadata_clean['rank'].str.split('in', expand=True)[0]\n",
    "metadata_clean['rank'] = pd.to_numeric(metadata_clean['rank'].str.replace(',', ''))\n",
    "metadata_clean['price'] = pd.to_numeric(metadata_clean['price'].str.replace('$', ''), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054eeba4",
   "metadata": {},
   "source": [
    "## 資料切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings = ratings[\n",
    "    (ratings['DATE'] < '2018-09-01')\n",
    "]\n",
    "ratings_testings = ratings[\n",
    "    (ratings['DATE'] >= '2018-09-01') & \n",
    "    (ratings['DATE'] <= '2018-09-30')\n",
    "]\n",
    "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
    "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
    "users = list(ratings_testings_by_user.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d5486",
   "metadata": {},
   "source": [
    "## 資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings = ratings_trainings.merge(metadata_clean[['asin', 'rank', 'price']], on='asin', how='left')\n",
    "ratings_trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1968d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56373e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings.drop(columns='unixReviewTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_group = ratings_trainings.groupby(by = 'asin').agg({'overall':['count', 'mean']})['overall'].rename(columns={'count':'sales', 'mean':'overall_mean'})\n",
    "overall_group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11018cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings = ratings_trainings.merge(overall_group, on='asin', how='left')\n",
    "ratings_trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d78d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings = (\n",
    "        ratings_trainings\n",
    "        .sort_values(\"DATE\", ascending=False)\n",
    "        .groupby(['reviewerID', 'asin']).head(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_trainings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_trainings = ratings_trainings[['asin', 'rank', 'price', 'sales', 'overall_mean', 'DATE']].sort_values(by='DATE', ascending=False).drop_duplicates(subset='asin', keep='first')\n",
    "asin_trainings.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d60d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_ratings = asin_trainings.sort_values(by = ['sales'], ascending=(False))['asin'].tolist()\n",
    "asin_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7d1ac",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41856997",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.pairplot(asin_trainings)\n",
    "plt.title(\"Looking for Insight in Data\")\n",
    "plt.tight_layout()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.histogram(ratings_trainings, \n",
    "                 x=\"overall\",\n",
    "                 hover_data=ratings_trainings.columns,\n",
    "                 title=\"Distribution of overall\",\n",
    "                 barmode=\"group\",\n",
    "                 text_auto=True\n",
    "                )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82644602",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(ratings_trainings,  \n",
    "             values=ratings_trainings['overall'].value_counts(),\n",
    "             names=ratings_trainings['overall'].value_counts().index,\n",
    "             title='Distribution of overall')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(ratings_trainings,  \n",
    "             values=ratings_trainings['reviewerID'].value_counts().value_counts(),\n",
    "             names=ratings_trainings['reviewerID'].value_counts().value_counts().index,\n",
    "             title='Distribution of buy_times')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f3731",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=px.histogram(ratings_trainings, \n",
    "                 x=\"DATE\",\n",
    "                 hover_data=ratings_trainings.columns,\n",
    "                 title=\"Distribution of date\",\n",
    "                 barmode=\"group\",\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61146b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.histogram(ratings_trainings, \n",
    "                 x=\"DATE\",\n",
    "                 color=\"overall\",\n",
    "                 hover_data=ratings_trainings.columns,\n",
    "                 title=\"Distribution of date & overall\",\n",
    "                 barmode=\"relative\",\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6b3ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=px.histogram(asin_trainings, \n",
    "                 x=\"overall_mean\",\n",
    "                 hover_data=asin_trainings.columns,\n",
    "                 title=\"Distribution of item average rating\",\n",
    "                 barmode=\"group\",\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ad4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(asin_trainings, \n",
    "                 x=\"sales\", \n",
    "                 y=\"rank\", \n",
    "#                  log_x=True,\n",
    "                 color=\"price\",\n",
    "                 size=\"overall_mean\", \n",
    "                 hover_data=asin_trainings.columns,\n",
    "                 title='Distribution of sales & rank'\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef9a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(asin_trainings, \n",
    "                 x=\"sales\", \n",
    "                 y=\"overall_mean\", \n",
    "#                  log_x=True,\n",
    "                 color=\"price\",\n",
    "                 size=\"overall_mean\",\n",
    "                 hover_data=asin_trainings.columns,\n",
    "                 title='Distribution of sales & overall_mean'\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(asin_trainings, \n",
    "                 x=\"sales\", \n",
    "                 y=\"price\", \n",
    "#                  log_x=True,\n",
    "#                  color=\"rank\",\n",
    "                 size=\"overall_mean\",\n",
    "                 hover_data=asin_trainings.columns,\n",
    "                 title='Distribution of sales & price'\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ff278",
   "metadata": {},
   "source": [
    "## 產生推薦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ffa9d",
   "metadata": {},
   "source": [
    "### User-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da997183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# header: user_id,item_id,rating,timestamp\n",
    "\n",
    "def user_based_recommender(training_data, users, k, days):\n",
    "    \n",
    "    if isinstance(days, int):\n",
    "        training_data = training_data[(training_data['DATE'] + datetime.timedelta(days = days)) > '2018-09-01']\n",
    "    ratings_trainings = training_data\n",
    "    ratings_info = ratings_trainings.groupby(by = ['asin'], as_index=False).agg(rating_count=('overall', 'size'), rating_mean=('overall', 'mean'))\n",
    "    asin_ratings = ratings_info.sort_values(by = ['rating_count'], ascending=(False))['asin'].tolist()\n",
    "    \n",
    "    # loading data from dataframe\n",
    "    # user_to_items dict:\n",
    "    # {\n",
    "    #   'user': {\n",
    "    #       'item': ratings...\n",
    "    #   }...\n",
    "    # }\n",
    "    user_to_items = defaultdict(dict)\n",
    "    for _, row in training_data.iterrows():\n",
    "        row = dict(row)\n",
    "        user = row['reviewerID']\n",
    "        item = row['asin']\n",
    "        rating = float(row['overall'])\n",
    "\n",
    "        user_to_items[user][item] = rating\n",
    "\n",
    "#     print(\"total users before filtering: \", len(user_to_items))\n",
    "\n",
    "    # remove obscure user to decrease data size\n",
    "    # filtering params\n",
    "    remove_obscure_user = True\n",
    "    user_rating_threshold = 3\n",
    "    all_users = list(user_to_items.keys())\n",
    "    for user in all_users:\n",
    "        ratings = user_to_items[user]\n",
    "        if remove_obscure_user and len(ratings) < user_rating_threshold:\n",
    "            del user_to_items[user]\n",
    "\n",
    "#     print(\"total users  after filtering: \", len(user_to_items))\n",
    "\n",
    "    # generate item to user mapping dict\n",
    "    # {\n",
    "    #   'item': {\n",
    "    #       'user': ratings...\n",
    "    #   }...\n",
    "    # }\n",
    "    item_to_users = defaultdict(dict)\n",
    "    for user, items in user_to_items.items():\n",
    "        for item, rating in items.items():\n",
    "            item_to_users[item][user] = rating\n",
    "\n",
    "    # prepare data of computing user similarity \n",
    "    init_sim = lambda: [0 for _ in range(3)]\n",
    "    factory = lambda: defaultdict(init_sim)\n",
    "    pre_user_similarity = defaultdict(factory)\n",
    "    n = len(item_to_users)\n",
    "    index = 0\n",
    "    for item, user_ratings in item_to_users.items():\n",
    "        if len(user_ratings) > 1:\n",
    "            # print(f\"item: {item} have been rated by {len(user_ratings)} users progress: {index}/{n}\")\n",
    "            for user1, user2 in combinations(user_ratings.keys(), 2):\n",
    "                xy = user_ratings[user1] * user_ratings[user2]\n",
    "                xx = user_ratings[user1] ** 2\n",
    "                yy = user_ratings[user2] ** 2\n",
    "                pre_user_similarity[user1][user2][0] += xy\n",
    "                pre_user_similarity[user1][user2][1] += xx\n",
    "                pre_user_similarity[user1][user2][2] += yy\n",
    "\n",
    "                pre_user_similarity[user2][user1][0] += xy\n",
    "                pre_user_similarity[user2][user1][1] += xx\n",
    "                pre_user_similarity[user2][user1][2] += yy\n",
    "        index += 1\n",
    "\n",
    "    user_similarity = {}\n",
    "    for src_user in pre_user_similarity:\n",
    "        user_similarity_order = []\n",
    "        for dst_user, val in pre_user_similarity[src_user].items():\n",
    "            xy = val[0]\n",
    "            xx = val[1]\n",
    "            yy = val[2]\n",
    "            div = ((xx*yy) ** 0.5)\n",
    "            if div == 0:\n",
    "                continue\n",
    "            similarity = xy / div\n",
    "            if similarity < 0:\n",
    "                continue\n",
    "            for i, s in enumerate(user_similarity_order):\n",
    "                target_similarity = s[1]\n",
    "                if target_similarity < similarity:\n",
    "                    user_similarity_order.insert(i, (dst_user, similarity))\n",
    "                    break\n",
    "            else:\n",
    "                user_similarity_order.append((dst_user, similarity))\n",
    "        user_similarity[src_user] = user_similarity_order\n",
    "\n",
    "    recommendation = {}\n",
    "    user_have_rated = set(user_to_items[user])\n",
    "    for user in users:\n",
    "        if user in user_similarity:\n",
    "            sim_users = user_similarity[user]\n",
    "            recommended_items = []\n",
    "            recommended_items_set = set()\n",
    "            user_have_rated = set(user_to_items[user])\n",
    "            stop_recommend = False\n",
    "            for sim_user, _ in sim_users:\n",
    "                items_from_sim_user = sorted(list(user_to_items[sim_user].items()), key=lambda item: item[1])\n",
    "                for item, _ in items_from_sim_user:\n",
    "                    if item not in user_have_rated and item not in recommended_items_set:\n",
    "                        recommended_items.append(item)\n",
    "                        recommended_items_set.add(item)\n",
    "                    if len(recommended_items) >= k:\n",
    "                        stop_recommend = True\n",
    "                        break\n",
    "                        \n",
    "                if len(recommended_items) < k:\n",
    "                    asin_list = [asin for asin in asin_ratings if asin not in user_have_rated and asin not in recommended_items_set]\n",
    "                    recommended_items.extend(asin_list)\n",
    "                    stop_recommend = True\n",
    "\n",
    "                if stop_recommend:\n",
    "                    break\n",
    "            recommendation[user] = recommended_items[:k]\n",
    "        else:\n",
    "            asin_list = [asin for asin in asin_ratings if asin not in user_have_rated]\n",
    "            recommendation[user] = asin_list[:k]\n",
    "\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03fc11",
   "metadata": {},
   "source": [
    "### Item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommender(training_data, users, k, days):\n",
    "    \n",
    "    if isinstance(days, int):\n",
    "        training_data = training_data[(training_data['DATE'] + datetime.timedelta(days = days)) > '2018-09-01']\n",
    "    ratings_trainings = training_data\n",
    "    ratings_info = ratings_trainings.groupby(by = ['asin'], as_index=False).agg(rating_count=('overall', 'size'), rating_mean=('overall', 'mean'))\n",
    "    asin_ratings = ratings_info.sort_values(by = ['rating_count'], ascending=(False))['asin'].tolist()\n",
    "    \n",
    "    # loading data from dataframe\n",
    "    # item_to_users dict:\n",
    "    # {\n",
    "    #   'item': {\n",
    "    #       'user': ratings...\n",
    "    #   }...\n",
    "    # }\n",
    "    item_to_users = defaultdict(dict)\n",
    "    for _, row in training_data.iterrows():\n",
    "        row = dict(row)\n",
    "        user = row['reviewerID']\n",
    "        item = row['asin']\n",
    "        rating = float(row['overall'])\n",
    "        item_to_users[item][user] = rating\n",
    "\n",
    "#     print(\"data converted\")\n",
    "\n",
    "    user_to_items = defaultdict(dict)\n",
    "    for item, rating_users in item_to_users.items():\n",
    "        for user, rating in rating_users.items():\n",
    "            user_to_items[user][item] = rating\n",
    "\n",
    "#     print(\"data inverted\")\n",
    "\n",
    "    init_sim = lambda: [0, 0, 0]\n",
    "    factory = lambda: defaultdict(init_sim)\n",
    "    pre_item_similarity = defaultdict(factory)\n",
    "    for user, items in user_to_items.items():\n",
    "        if len(items) > 1:\n",
    "            for i1, i2 in combinations(items.keys(), 2):\n",
    "                xy = items[i1] * items[i2]\n",
    "                xx = items[i1] ** 2\n",
    "                yy = items[i2] ** 2\n",
    "                pre_item_similarity[i1][i2][0] += xy\n",
    "                pre_item_similarity[i1][i2][1] += xx\n",
    "                pre_item_similarity[i1][i2][2] += yy\n",
    "\n",
    "                pre_item_similarity[i2][i1][0] += xy\n",
    "                pre_item_similarity[i2][i1][1] += xx\n",
    "                pre_item_similarity[i2][i1][2] += yy\n",
    "\n",
    "#     print(\"sim data prepared\")\n",
    "\n",
    "    item_similarity = {}\n",
    "    for src_item in pre_item_similarity:\n",
    "        item_similarity_order = []\n",
    "        for dst_item, val in pre_item_similarity[src_item].items():\n",
    "            xy = val[0]\n",
    "            xx = val[1]\n",
    "            yy = val[2]\n",
    "            div = ((xx*yy) ** 0.5)\n",
    "            if div == 0:\n",
    "                continue\n",
    "            similarity = xy / div\n",
    "            if similarity < 0:\n",
    "                continue\n",
    "            for i, s in enumerate(item_similarity_order):\n",
    "                target_similarity = s[1]\n",
    "                if target_similarity < similarity:\n",
    "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
    "                    break\n",
    "            else:\n",
    "                item_similarity_order.append((dst_item, similarity))\n",
    "        item_similarity[src_item] = item_similarity_order\n",
    "\n",
    "#     print(f\"get {k} recommendation items for for user: {users}\")\n",
    "\n",
    "    recommendation = {}\n",
    "    for user in users:\n",
    "        items = []\n",
    "        items_set = set()\n",
    "        stop = False\n",
    "        user_has_rated = set(user_to_items[user])\n",
    "        for item in user_has_rated:\n",
    "            if item in item_similarity:\n",
    "                for sim_item, _ in item_similarity[item]:\n",
    "                    # skip the item user has rated\n",
    "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
    "                        items.append(sim_item)\n",
    "                        items_set.add(sim_item)\n",
    "                    if len(items) >= k:\n",
    "                        stop = True\n",
    "                        break\n",
    "                        \n",
    "            if len(items) < k:\n",
    "                asin_list = [asin for asin in asin_ratings if asin not in user_has_rated and asin not in items_set]\n",
    "                items.extend(asin_list)\n",
    "                stop = True\n",
    "                \n",
    "            if stop:\n",
    "                break\n",
    "        \n",
    "        if items:\n",
    "            recommendation[user] = items[:k]\n",
    "        else:\n",
    "            asin_list = [asin for asin in asin_ratings if asin not in user_has_rated]\n",
    "            recommendation[user] = asin_list[:k]\n",
    "  \n",
    "    return recommendation   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e992f2",
   "metadata": {},
   "source": [
    "### Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_recommender(training_data, users, k, days, user_based=False, algo=KNNBasic):\n",
    "    \n",
    "    if isinstance(days, int):\n",
    "        training_data = training_data[(training_data['DATE'] + datetime.timedelta(days = days)) > '2018-09-01']\n",
    "    ratings_trainings = training_data\n",
    "    ratings_info = ratings_trainings.groupby(by = ['asin'], as_index=False).agg(rating_count=('overall', 'size'), rating_mean=('overall', 'mean'))\n",
    "    asin_ratings = ratings_info.sort_values(by = ['rating_count'], ascending=(False))['asin'].tolist()\n",
    "    \n",
    "    reader = Reader(rating_scale=(0, 5))\n",
    "    training_data = training_data[['reviewerID', 'asin', 'overall']]\n",
    "    data = Dataset.load_from_df(training_data, reader=reader)\n",
    "\n",
    "    sim_options = {\n",
    "        'name': 'cosine',\n",
    "        'user_based': user_based  # compute similarities between items\n",
    "    }\n",
    "    algo_impl = algo(sim_options=sim_options)\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo_impl.fit(trainset)\n",
    "\n",
    "    recommendation = {}\n",
    "    for user in users:\n",
    "        items_user_rated = set(training_data.loc[training_data['reviewerID'] == user]['asin'].to_list())\n",
    "        recommend_item_list = []\n",
    "        recommend_item_set = set()\n",
    "        for item in items_user_rated:\n",
    "            iid = algo_impl.trainset.to_inner_iid(item)\n",
    "            recommend_items_iid = algo_impl.get_neighbors(iid, k)\n",
    "            for sim_item_iid in recommend_items_iid:\n",
    "                item_raw_id = algo_impl.trainset.to_raw_iid(sim_item_iid)\n",
    "                if item_raw_id not in items_user_rated and item_raw_id not in recommend_item_set:\n",
    "                    recommend_item_list.append(item_raw_id)\n",
    "                    recommend_item_set.add(item_raw_id)\n",
    "\n",
    "            if len(recommend_item_list) >= k:\n",
    "                recommend_item_list = recommend_item_list[:k]\n",
    "                break\n",
    "                \n",
    "            if len(recommend_item_list) < k:\n",
    "                asin_list = [asin for asin in asin_ratings if asin not in items_user_rated and asin not in recommend_item_set]\n",
    "                recommend_item_list.extend(asin_list)\n",
    "        \n",
    "        if recommend_item_list:\n",
    "            recommendation[user] = recommend_item_list[:k]\n",
    "        else:\n",
    "            asin_list = [asin for asin in asin_ratings if asin not in items_user_rated]\n",
    "            recommendation[user] = asin_list[:k]\n",
    "\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4ca9e",
   "metadata": {},
   "source": [
    "## 結果評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee763747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
    "    '''\n",
    "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
    "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
    "    * method: str\n",
    "    * score: float\n",
    "    '''\n",
    "    total = 0\n",
    "    for d in ratings_testings_by_user:\n",
    "        if d in ratings_by_user:\n",
    "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
    "\n",
    "    score = total / len(ratings_testings)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-based\n",
    "score_list = []\n",
    "k_list = [5, 10, 30]\n",
    "days_list = [30, 60, 90, 180, 'All']\n",
    "for k in k_list:\n",
    "    for days in days_list:\n",
    "        ratings_by_user = user_based_recommender(ratings_trainings, users, k, days)\n",
    "        score = evaluate(ratings_testings_by_user, ratings_by_user)\n",
    "        score_list.append(score)\n",
    "\n",
    "user_result_df = pd.DataFrame(np.reshape(score_list, (3, 5)).T, index=pd.Index(days_list, name='Days'), columns=pd.Index(k_list, name='K'))\n",
    "user_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-based\n",
    "score_list = []\n",
    "k_list = [5, 10, 30]\n",
    "days_list = [30, 60, 90, 180, 'All']\n",
    "for k in k_list:\n",
    "    for days in days_list:\n",
    "        ratings_by_user = item_based_recommender(ratings_trainings, users, k, days)\n",
    "        score = evaluate(ratings_testings_by_user, ratings_by_user)\n",
    "        score_list.append(score)\n",
    "\n",
    "item_result_df = pd.DataFrame(np.reshape(score_list, (3, 5)).T, index=pd.Index(days_list, name='Days'), columns=pd.Index(k_list, name='K'))\n",
    "item_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53055ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# surprise\n",
    "score_list = []\n",
    "k_list = [5, 10, 30]\n",
    "days_list = [30, 60, 90, 180, 360]\n",
    "for k in k_list:\n",
    "    for days in days_list:\n",
    "        ratings_by_user = surprise_recommender(ratings_trainings, users, k, days)\n",
    "        score = evaluate(ratings_testings_by_user, ratings_by_user)\n",
    "        score_list.append(score)\n",
    "\n",
    "surprise_result_df = pd.DataFrame(np.reshape(score_list, (3, 5)).T, index=pd.Index(days_list, name='Days'), columns=pd.Index(k_list, name='K'))\n",
    "surprise_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32832838",
   "metadata": {},
   "source": [
    "## 檢查訓練集與測試集的使用者交集購買次數狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a853c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(set(ratings_trainings[ratings_trainings['reviewerID'].isin(users)]['reviewerID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcde104",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_user = ratings_trainings[ratings_trainings['reviewerID'].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2eba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dup_user = dup_user.groupby(by='reviewerID').agg({'asin':'count'})['asin'].reset_index().rename(columns={'asin':'buy_times'})\n",
    "dup_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a340e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(dup_user,  \n",
    "             values=dup_user['buy_times'].value_counts(),\n",
    "             names=dup_user['buy_times'].value_counts().index,\n",
    "             title='Distribution of 38 user buy_times')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
